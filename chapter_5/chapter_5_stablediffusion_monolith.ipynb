{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monolith architecture\n",
    "\n",
    "In this architecture, we only have one large component which contains everything. In this example, we do not have a database, because we focus only on the inference, but we could add a database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, log in for the StableDiffusion models\n",
    "from huggingface_hub import login\n",
    "\n",
    "\n",
    "# this is my login token, please do not spread it\n",
    "# so this file is not to be made public\n",
    "login(token=\"YOUR TOKEN HERE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, this is a code that contains only the stable diffusion model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stable diffusion from HuggingFace\n",
    "import torch\n",
    "from diffusers import StableDiffusion3Pipeline\n",
    "\n",
    "pipe = StableDiffusion3Pipeline.from_pretrained(\"stabilityai/stable-diffusion-3.5-large\", torch_dtype=torch.bfloat16)\n",
    "pipe = pipe.to(\"cuda\")\n",
    "\n",
    "image = pipe(\n",
    "    \"A capybara holding a sign that reads Hello World\",\n",
    "    num_inference_steps=28,\n",
    "    guidance_scale=3.5,\n",
    ").images[0]\n",
    "image.save(\"capybara.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This one contains even the interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from diffusers import StableDiffusion3Pipeline\n",
    "import gradio as gr\n",
    "\n",
    "# Load the Stable Diffusion model\n",
    "# big model for big GPUs\n",
    "#pipe = StableDiffusion3Pipeline.from_pretrained(\"stabilityai/stable-diffusion-3.5-medium\", \n",
    "#                                                torch_dtype=torch.bfloat16)\n",
    "\n",
    "# and a smaller version for laptops\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\"stabilityai/stable-diffusion-2-1-base\", torch_dtype=torch.float16)\n",
    "\n",
    "pipe = pipe.to(\"cuda\")\n",
    "\n",
    "# Define a function to generate an image based on user input\n",
    "def generate_image(prompt):\n",
    "    image = pipe(\n",
    "        prompt,\n",
    "        num_inference_steps=28,\n",
    "        guidance_scale=3.5,\n",
    "    ).images[0]\n",
    "    return image\n",
    "\n",
    "# Create a Gradio interface\n",
    "iface = gr.Interface(fn=generate_image, inputs=\"text\", outputs=\"image\")\n",
    "\n",
    "# Launch the interface\n",
    "iface.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
